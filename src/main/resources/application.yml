server:
  port: 5013
  servlet:
    context-path: /content
spring:
  application:
    name: hangout-content-service
  datasource:
    driverClassName: org.postgresql.Driver
    url: jdbc:postgresql://${CLUSTER_URL}/${DB_NAME}
    username: ${DB_USERNAME}
    password: ${DB_PASSWORD}
  servlet:
    multipart:
      max-file-size: 5GB
      max-request-size: 5223MB # aprx 5.1 GB
  jpa:
    properties:
      hibernate:
        "[format_sql]": true
    hibernate:
      ddl-auto: update
    show-sql: true
  output:
    ansi:
      enabled: ALWAYS
  kafka:
    bootstrap-servers: ${KAFKA_SERVER}
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer

# All traces should be sent to latency analysis tool
management:
  tracing:
    sampling:
      probability: 1.0
  endpoints:
    web:
      exposure:
        include: prometheus, health
  # For Exemplars to work we need histogram buckets
  metrics:
    distribution:
      percentiles-histogram:
        http:
          server:
            requests: true

springdoc:
  api-docs:
    path: /api-docs
  swagger-ui:
    path: /swagger-ui

logging:
  level:
    web: error
    sql: error
    "[org.springframework.security]": error
    "[com.hangout.core]": trace
    # traceID and spanId are predefined MDC keys - we want the logs to include them
  pattern:
    level: "%5p [${spring.application.name:},%X{traceId:-},%X{spanId:-}]"

hangout:
  kafka:
    topic: content
  auth-service:
    url: ${AUTH_SERVICE}
  storage-service:
    path: ${STORAGE_PATH}
  loki-server:
    url: ${LOKI_SERVER}
  tempo-server:
    url: ${TEMPO_SERVER}
  log:
    path: ${LOG_DIR}
